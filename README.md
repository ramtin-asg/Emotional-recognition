# Emotion Recognition Using Deep Learning

This repository contains the code, resources, and documentation for my Bachelor's thesis at **Amirkabir University of Technology (Tehran Polytechnic)**.

---

## **Table of Contents**
- [About the Project](#about-the-project)
- [Dataset](#dataset)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Acknowledgments](#acknowledgments)

---

## **About the Project**
This project focuses on emotion recognition using deep learning techniques. The goal is to classify human emotions based on data (e.g., images, audio, or text) with high accuracy.
     Understanding customers' emotions for jobs and businesses is provided by using updated and new technologies in this project. These technologies can be applied the sellig process at the best moment according to the consumer sentiment analysis. Emotional intelligence is a growing knowledge that has influence in notonly commercial purposes butalso in new start - ups, health care, wearable digital tools, human-robot communication, education, and  etc with a great impact.
Increasing importance in accuracy has led us to the use of computer-aided diagnosis systems. In this project, we try to study power of deep learning to recognize facial expressions and improve the performance of the classifiers. For this purpose, the common and available dataset which is named FER-2013 is used.
In this project, we applied the convolution neural network (cnn) for real-time system design. Then we validate   our model to perform facial recognition tasks and emotion classification by accuracy. The results show the improvment of emotion recognition in terms of accuracy increases to 71%.

**University:** Amirkabir University of Technology (Tehran Polytechnic)  
**Faculty:** Electrical Engineering  
**Advisor:** Dr. F. Abdollahi  
**Author:** Ramtin Asgarianamiri  
## **Dataset**
The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image.
The task is to categorize each face based on the emotion shown in the facial expression into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The training set consists of 28,709 examples and the public test set consists of 3,589 examples.
you can easily access it here: https://www.kaggle.com/datasets/msambare/fer2013
## **Usage and Results**
The development of deep learning techniques and neural networks in various fields, including emotion and facial recognition for individual classification, has seen remarkable advancements. These improvements have led to real-time accuracy and speed, often surpassing human capabilities in some areas, particularly in marketing and enhancing understanding of individuals and their emotions.
In the field of robotics and human-robot interaction, this topic requires addressing various aspects such as age, gender, and ethnicity. Notably, selecting appropriate models tailored to the characteristics of the dataset is crucial for achieving acceptable results. Efforts in dataset preparation can significantly enhance network performance.
In this project, a proposed model inspired by the Xception architecture aimed to first achieve facial recognition and subsequently classify emotions into seven categories based on general ethical philosophy criteria. The use of the FER dataset was instrumental in realizing this goal by providing high diversity and accurate labeling.
This model achieved an accuracy of approximately 67% in the ImageNet challenge, earning global recognition. By increasing the parameters, the project improved accuracy to about 71%, demonstrating better precision and higher efficiency for this architecture.
Therefore, it can be concluded that leveraging complex neural network models for emotion recognition, alongside optimization, is highly beneficial. This is particularly significant in human-robot interaction and marketing domains.
![Screenshot (121)](https://github.com/user-attachments/assets/3e1f82bf-35d5-4ae1-b2d9-27ee7f9c9467)


